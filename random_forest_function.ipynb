{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6416da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pylab as plt\n",
    "# get functions from utils.py\n",
    "from utils import eval_metrics,plot_train_test,train_data_ml\n",
    "from joblib import dump\n",
    "import gc\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import glob\n",
    "import joblib\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbcea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ari = pd.read_csv(\"data_ari.csv\",sep=\",\",dtype={'location':str,'year_week':str,\n",
    "                                                'value':np.float32,'relative_humidity_2m':np.float64,\n",
    "                                                'temperature_2m_max':np.float64,'temperature_2m_min':np.float64},\n",
    "                                                parse_dates=['truth_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7100839",
   "metadata": {},
   "outputs": [],
   "source": [
    "ili = pd.read_csv(\"data_ili.csv\",sep=\",\",dtype={'location':str,'year_week':str,\n",
    "                                                'value':np.float32,'relative_humidity_2m':np.float64,\n",
    "                                                'temperature_2m_max':np.float64,'temperature_2m_min':np.float64},\n",
    "                                                parse_dates=['truth_date'])\n",
    "ili = ili.drop(columns=['Unnamed: 0']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5429071",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ari = pd.DataFrame(columns=['location','model','prediction_window','mae','rmse'])\n",
    "mape_ili = pd.DataFrame(columns=['location','model','prediction_window','mae','rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e4b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_variable_selection_and_hyperparam_tuning(train,test,country =None, model_name=None, mape=None):\n",
    "    X = train.drop(columns=['value','week_mas_1','week_mas_2','week_mas_3'])\n",
    "    y = train[['value','week_mas_1','week_mas_2','week_mas_3']]\n",
    "\n",
    "    X_test = test.drop(columns=['value','week_mas_1','week_mas_2','week_mas_3'])\n",
    "    y_test= test[['value','week_mas_1','week_mas_2','week_mas_3']]\n",
    "    \n",
    "\n",
    "    base_rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=2332))\n",
    "    base_rf.fit(X, y)\n",
    "\n",
    "    importances = np.array([est.feature_importances_ for est in base_rf.estimators_])\n",
    "\n",
    "    mean_importances = importances.mean(axis=0)\n",
    "\n",
    "\n",
    "    selected_mask = mean_importances >= 0.01\n",
    "    selected_features = X.columns[selected_mask].tolist()\n",
    "    X_selected = X[selected_features]\n",
    "\n",
    "    # Step 3: Hyperparameter tuning with RandomizedSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_depth': [5,10, 20, 30, None],\n",
    "        'min_samples_split': [2,4, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4,5],\n",
    "        'max_features': ['sqrt', 'log2']\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    rf = RandomForestRegressor(random_state=2332)\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=rf,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=20,\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        random_state=2332\n",
    "    )\n",
    "\n",
    "    random_search.fit(X_selected, y)\n",
    "\n",
    "    best_model = random_search.best_estimator_\n",
    "    model_final = MultiOutputRegressor(best_model)\n",
    "    model_final.fit(X_selected, y)\n",
    "    model_final.selected_features_ = selected_features\n",
    "    model_final.country_ = country\n",
    "    model_final.model_name_ = model_name\n",
    "\n",
    "    dump(model_final, f\"models_rf/rf_model_{country}_{model_name}.joblib\")\n",
    "    test_aux = test.copy()\n",
    "    prediction_columns = [f\"prediction_{h+1}_weeks\" for h in range(4)]\n",
    "    preds = model_final.predict(X_test[selected_features])\n",
    "    test_aux[prediction_columns] = preds\n",
    "    pred_df = pd.DataFrame(preds, index=X_test.index, columns=prediction_columns)\n",
    "    pred_df['value'] = y_test['value'].values\n",
    "    print(pred_df.head())\n",
    "    # Evaluate predictions\n",
    "    test_aux = test_aux.dropna()\n",
    "    mae0, rmse0 = eval_metrics(test_aux[\"value\"], test_aux[\"prediction_1_weeks\"])\n",
    "    mae1, rmse1  = eval_metrics(test_aux[\"week_mas_1\"], test_aux[\"prediction_2_weeks\"])\n",
    "    mae2, rmse2  = eval_metrics(test_aux[\"week_mas_2\"], test_aux[\"prediction_3_weeks\"])\n",
    "    mae3, rmse3 = eval_metrics(test_aux[\"week_mas_3\"], test_aux[\"prediction_4_weeks\"])\n",
    "\n",
    "    mape = pd.concat([\n",
    "    mape,\n",
    "    pd.DataFrame([\n",
    "        [country, model_name, \"1_week\", mae0, rmse0],\n",
    "        [country, model_name, \"2_week\", mae1, rmse1],\n",
    "        [country, model_name, \"3_week\", mae2, rmse2],\n",
    "        [country, model_name, \"4_week\", mae3, rmse3]\n",
    "    ], columns=['location', 'model', 'prediction_window', 'mae', 'rmse'])\n",
    "], ignore_index=True)\n",
    "    return model_final, selected_features, pred_df,mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd401294",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ari = pd.DataFrame(columns=['location','model','prediction_window','mae','rmse'])\n",
    "mape_ili = pd.DataFrame(columns=['location','model','prediction_window','mae','rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_ari = ari.location.unique()\n",
    "name_ili = ili.location.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35fe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in name_ari:\n",
    "    print(f\"Processing location: {i}\")\n",
    "    train, test = train_data_ml(ari,i, \"2023-10-13\")\n",
    "    train = train.drop(columns=['location'])\n",
    "    test = test.drop(columns=['location'])\n",
    "    model_final, selected_features, test_aux,mape_ari= rf_variable_selection_and_hyperparam_tuning(train,test,country =i, model_name='ARI', mape=mape_ari)\n",
    "    test_aux.to_csv(f'results_rf_{i}_ari.csv',index=False)\n",
    "    plot_train_test(train, test_aux,\"ARI\",i,'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbfd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ari.to_csv(\"mape_ari_rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67417d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in name_ili:\n",
    "    print(f\"Processing location: {i}\")\n",
    "    train, test = train_data_ml(ili,i, \"2023-10-13\")\n",
    "    train = train.drop(columns=['location'])\n",
    "    test = test.drop(columns=['location'])\n",
    "    model_final, selected_features, test_aux,mape_ili= rf_variable_selection_and_hyperparam_tuning(train,test,country =i, model_name='ILI', mape=mape_ili)\n",
    "    test_aux.to_csv(f'results_rf_{i}_ili.csv',index=False)\n",
    "    plot_train_test(train, test_aux,\"ILI\",i,'RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0311e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cf8af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_ili.to_csv(\"mape_ili_rf.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7da8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for path in glob.glob(\"models_rf/rf_model_*_*.joblib\"):\n",
    "    model = joblib.load(path)\n",
    "\n",
    "    # Extract country and model name from filename if not stored in model\n",
    "    m = re.search(r\"rf_model_(.+?)_(.+?)\\.joblib$\", path)\n",
    "    country = getattr(model, \"country_\", m.group(1) if m else \"UNK\")\n",
    "    model_name = getattr(model, \"model_name_\", m.group(2) if m else \"UNK\")\n",
    "\n",
    "    # Recover selected features\n",
    "    if hasattr(model, \"selected_features_\"):\n",
    "        feats = model.selected_features_\n",
    "    else:\n",
    "        try:\n",
    "            feats = list(model.estimators_[0].feature_names_in_)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"No feature names available for {path}. \"\n",
    "                             \"Please re-save with .selected_features_\")\n",
    "\n",
    "    # Extract feature importances for each horizon\n",
    "    for h_idx, est in enumerate(model.estimators_, start=1):\n",
    "        imps = est.feature_importances_\n",
    "        rows.extend([\n",
    "            {\"country\": country, \"model_name\": model_name,\n",
    "             \"horizon\": h_idx, \"feature\": f, \"importance\": imp}\n",
    "            for f, imp in zip(feats, imps)\n",
    "        ])\n",
    "\n",
    "all_imp = pd.DataFrame(rows)\n",
    "all_imp.to_csv(\"rf_feature_importances.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d249b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_disease(name):\n",
    "    name = name.lower()\n",
    "    if \"ari\" in name:\n",
    "        return \"ARI\"\n",
    "    elif \"ili\" in name:\n",
    "        return \"ILI\"\n",
    "    else:\n",
    "        return \"UNK\"\n",
    "\n",
    "all_imp[\"disease\"] = all_imp[\"model_name\"].map(extract_disease)\n",
    "# Compute mean and std importance per feature per disease\n",
    "feat_stats = (\n",
    "    all_imp\n",
    "    .groupby([\"disease\", \"feature\"])[\"importance\"]\n",
    "    .agg([\"mean\", \"std\"])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Sort within each disease and select top 10\n",
    "top10 = (\n",
    "    feat_stats\n",
    "    .sort_values([\"disease\", \"mean\"], ascending=[True, False])\n",
    "    .groupby(\"disease\")\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- ARI ----\n",
    "feat_stats_ari = (\n",
    "    feat_stats[feat_stats[\"disease\"] == \"ARI\"]\n",
    "    .sort_values(\"mean\", ascending=True)\n",
    "    .tail(10)   # top 10\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feat_stats_ari[\"feature\"], feat_stats_ari[\"mean\"], xerr=feat_stats_ari[\"std\"])\n",
    "plt.xlabel(\"Mean Importance\")\n",
    "plt.title(\"Top 10 Random Forest Features – ARI\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rf_feature_importance_ARI.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---- ILI ----\n",
    "feat_stats_ili = (\n",
    "    feat_stats[feat_stats[\"disease\"] == \"ILI\"]\n",
    "    .sort_values(\"mean\", ascending=True)\n",
    "    .tail(10)   # top 10\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.barh(feat_stats_ili[\"feature\"], feat_stats_ili[\"mean\"], xerr=feat_stats_ili[\"std\"])\n",
    "plt.xlabel(\"Mean Importance\")\n",
    "plt.title(\"Top 10 Random Forest Features – ILI\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"rf_feature_importance_ILI.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
